{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "from six.moves import range\n",
    "import openslide\n",
    "import tensorflow as tf\n",
    "from torchvision import transforms  # noqa\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.filters import threshold_otsu\n",
    "from tensorflow.keras import backend as K\n",
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinMorphoProcessMask(mask):\n",
    "    \"\"\"\n",
    "    Binary operation performed on tissue mask\n",
    "    \"\"\"\n",
    "    close_kernel = np.ones((20, 20), dtype=np.uint8)\n",
    "    image_close = cv2.morphologyEx(np.array(mask), cv2.MORPH_CLOSE, close_kernel)\n",
    "    open_kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "    image_open = cv2.morphologyEx(np.array(image_close), cv2.MORPH_OPEN, open_kernel)\n",
    "    return image_open\n",
    "\n",
    "def get_bbox(cont_img, rgb_image=None):\n",
    "    contours, _ = cv2.findContours(cont_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rgb_contour = None\n",
    "    if rgb_image is not None:\n",
    "        rgb_contour = rgb_image.copy()\n",
    "        line_color = (0, 0, 255)  # blue color code\n",
    "        cv2.drawContours(rgb_contour, contours, -1, line_color, 2)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        rgb_contour = cv2.rectangle(rgb_contour,(x,y),(x+h,y+w),(0,255,0),2)\n",
    "    return bounding_boxes, rgb_contour\n",
    "\n",
    "def get_all_bbox_masks_with_stride(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the bbox and corresponding masks\n",
    "    \"\"\"\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    bounding_boxes, _ = get_bbox(mask)\n",
    "    y_size, x_size = bbox_mask.shape\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        x_min = x - stride_factor\n",
    "        x_max = x + h + stride_factor\n",
    "        y_min = y - stride_factor\n",
    "        y_max = y + w + stride_factor\n",
    "        if x_min < 0: \n",
    "         x_min = 0\n",
    "        if y_min < 0: \n",
    "         y_min = 0\n",
    "        if x_max > x_size: \n",
    "         x_max = x_size - 1\n",
    "        if y_max > y_size: \n",
    "         y_max = y_size - 1      \n",
    "        bbox_mask[y_min:y_max:stride_factor, x_min:x_max:stride_factor]=1\n",
    "        \n",
    "    return bbox_mask\n",
    "\n",
    "\n",
    "def get_all_bbox_masks(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the bbox and corresponding masks\n",
    "    \"\"\"\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    bounding_boxes, _ = get_bbox(mask)\n",
    "    y_size, x_size = bbox_mask.shape\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        x_min = x - stride_factor\n",
    "        x_max = x + h + stride_factor\n",
    "        y_min = y - stride_factor\n",
    "        y_max = y + w + stride_factor\n",
    "        if x_min < 0: \n",
    "         x_min = 0\n",
    "        if y_min < 0: \n",
    "         y_min = 0\n",
    "        if x_max > x_size: \n",
    "         x_max = x_size - 1\n",
    "        if y_max > y_size: \n",
    "         y_max = y_size - 1      \n",
    "        bbox_mask[y_min:y_max, x_min:x_max]=1\n",
    "    return bbox_mask\n",
    "\n",
    "def find_largest_bbox(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the largest bounding box encompassing all the blobs\n",
    "    \"\"\"\n",
    "    y_size, x_size = mask.shape\n",
    "    x, y = np.where(mask==1)\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    x_min = np.min(x) - stride_factor\n",
    "    x_max = np.max(x) + stride_factor\n",
    "    y_min = np.min(y) - stride_factor\n",
    "    y_max = np.max(y) + stride_factor\n",
    "    \n",
    "    if x_min < 0: \n",
    "     x_min = 0\n",
    "    \n",
    "    if y_min < 0: \n",
    "     y_min = 0\n",
    "\n",
    "    if x_max > x_size: \n",
    "     x_max = x_size - 1\n",
    "    \n",
    "    if y_max > y_size: \n",
    "     y_max = y_size - 1    \n",
    "    \n",
    "    # print(x_min, x_max, y_min, y_max)\n",
    "    bbox_mask[x_min:x_max, y_min:y_max]=1\n",
    "    return bbox_mask\n",
    "\n",
    "def TissueMaskGeneration(slide_obj, level, RGB_min=50):\n",
    "    img_RGB = np.transpose(np.array(slide_obj.read_region((0, 0),\n",
    "                       level,\n",
    "                       slide_obj.level_dimensions[level]).convert('RGB')),\n",
    "                       axes=[1, 0, 2])\n",
    "    img_HSV = rgb2hsv(img_RGB)\n",
    "    background_R = img_RGB[:, :, 0] > threshold_otsu(img_RGB[:, :, 0])\n",
    "    background_G = img_RGB[:, :, 1] > threshold_otsu(img_RGB[:, :, 1])\n",
    "    background_B = img_RGB[:, :, 2] > threshold_otsu(img_RGB[:, :, 2])\n",
    "    tissue_RGB = np.logical_not(background_R & background_G & background_B)\n",
    "    tissue_S = img_HSV[:, :, 1] > threshold_otsu(img_HSV[:, :, 1])\n",
    "    min_R = img_RGB[:, :, 0] > RGB_min\n",
    "    min_G = img_RGB[:, :, 1] > RGB_min\n",
    "    min_B = img_RGB[:, :, 2] > RGB_min\n",
    "\n",
    "    tissue_mask = tissue_S & tissue_RGB & min_R & min_G & min_B\n",
    "    return tissue_mask\n",
    "\n",
    "def labelthreshold(image, threshold=0.5):\n",
    "    label = np.zeros_like(image)\n",
    "    label[image >= threshold] = 1\n",
    "    return label\n",
    "\n",
    "def normalize_minmax(data):\n",
    "    \"\"\"\n",
    "    Normalize contrast across volume\n",
    "    \"\"\"\n",
    "    _min = np.float(np.min(data))\n",
    "    _max = np.float(np.max(data))\n",
    "    if (_max-_min)!=0:\n",
    "        img = (data - _min) / (_max-_min)\n",
    "    else:\n",
    "        img = np.zeros_like(data)            \n",
    "    return img\n",
    "    \n",
    "# Image Helper Functions\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage:\n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    axis_off = kwargs.get('axis_off','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "            if axis_off: \n",
    "              plt.axis('off')  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSIStridedPatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Data producer that generate all the square grids, e.g. 3x3, of patches,\n",
    "    from a WSI and its tissue mask, and their corresponding indices with\n",
    "    respect to the tissue mask\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_path, mask_path, label_path=None, image_size=256,\n",
    "                 normalize=True, flip='NONE', rotate='NONE',                \n",
    "                 level=5, sampling_stride=16, roi_masking=True):\n",
    "        \"\"\"\n",
    "        Initialize the data producer.\n",
    "\n",
    "        Arguments:\n",
    "            wsi_path: string, path to WSI file\n",
    "            mask_path: string, path to mask file in numpy format OR None\n",
    "            label_mask_path: string, path to ground-truth label mask path in tif file or\n",
    "                            None (incase of Normal WSI or test-time)\n",
    "            image_size: int, size of the image before splitting into grid, e.g. 768\n",
    "            patch_size: int, size of the patch, e.g. 256\n",
    "            crop_size: int, size of the final crop that is feed into a CNN,\n",
    "                e.g. 224 for ResNet\n",
    "            normalize: bool, if normalize the [0, 255] pixel values to [-1, 1],\n",
    "                mostly False for debuging purpose\n",
    "            flip: string, 'NONE' or 'FLIP_LEFT_RIGHT' indicating the flip type\n",
    "            rotate: string, 'NONE' or 'ROTATE_90' or 'ROTATE_180' or\n",
    "                'ROTATE_270', indicating the rotate type\n",
    "            level: Level to extract the WSI tissue mask\n",
    "            roi_masking: True: Multiplies the strided WSI with tissue mask to eliminate white spaces,\n",
    "                                False: Ensures inference is done on the entire WSI   \n",
    "            sampling_stride: Number of pixels to skip in the tissue mask, basically it's the overlap\n",
    "                            fraction when patches are extracted from WSI during inference.\n",
    "                            stride=1 -> consecutive pixels are utilized\n",
    "                            stride= image_size/pow(2, level) -> non-overalaping patches \n",
    "        \"\"\"\n",
    "        self._wsi_path = wsi_path\n",
    "        self._mask_path = mask_path\n",
    "        self._label_path = label_path\n",
    "        self._image_size = image_size\n",
    "        self._normalize = normalize\n",
    "        self._flip = flip\n",
    "        self._rotate = rotate\n",
    "        self._level = level\n",
    "        self._sampling_stride = sampling_stride\n",
    "        self._roi_masking = roi_masking\n",
    "        self._preprocess()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self._slide = openslide.OpenSlide(self._wsi_path)\n",
    "        X_slide, Y_slide = self._slide.level_dimensions[0]\n",
    "        factor = self._sampling_stride\n",
    "\n",
    "        if self._label_path is not None:\n",
    "            self._label_slide = openslide.OpenSlide(self._label_path)\n",
    "        \n",
    "        if self._mask_path is not None:\n",
    "            mask_file_name = os.path.basename(self._mask_path)\n",
    "            if mask_file_name.endswith('.npy'):\n",
    "                self._mask = np.load(self._mask_path)\n",
    "            if mask_file_name.endswith('.tif'):\n",
    "                mask_obj = openslide.OpenSlide(self._mask_path)\n",
    "                self._mask = np.array(mask_obj.read_region((0, 0),\n",
    "                       level,\n",
    "                       mask_obj.level_dimensions[level]).convert('L')).T\n",
    "        else:\n",
    "            # Generate tissue mask on the fly    \n",
    "            self._mask = TissueMaskGeneration(self._slide, self._level)\n",
    "           \n",
    "        # morphological operations ensure the holes are filled in tissue mask\n",
    "        # and minor points are aggregated to form a larger chunk         \n",
    "\n",
    "        # self._mask = BinMorphoProcessMask(np.uint8(self._mask))\n",
    "        # self._all_bbox_mask = get_all_bbox_masks(self._mask, factor)\n",
    "        # self._largest_bbox_mask = find_largest_bbox(self._mask, factor)\n",
    "        # self._all_strided_bbox_mask = get_all_bbox_masks_with_stride(self._mask, factor)\n",
    "\n",
    "        X_mask, Y_mask = self._mask.shape\n",
    "        # print (self._mask.shape, np.where(self._mask>0))\n",
    "        # imshow(self._mask.T)\n",
    "        # cm17 dataset had issues with images being power's of 2 precisely        \n",
    "        if X_slide // X_mask != Y_slide // Y_mask:\n",
    "            raise Exception('Slide/Mask dimension does not match ,'\n",
    "                            ' X_slide / X_mask : {} / {},'\n",
    "                            ' Y_slide / Y_mask : {} / {}'\n",
    "                            .format(X_slide, X_mask, Y_slide, Y_mask))\n",
    "\n",
    "        self._resolution = np.round(X_slide * 1.0 / X_mask)\n",
    "        if not np.log2(self._resolution).is_integer():\n",
    "            raise Exception('Resolution (X_slide / X_mask) is not power of 2 :'\n",
    "                            ' {}'.format(self._resolution))\n",
    "             \n",
    "        # all the idces for tissue region from the tissue mask  \n",
    "        self._strided_mask =  np.ones_like(self._mask)\n",
    "        ones_mask = np.zeros_like(self._mask)\n",
    "        ones_mask[::factor, ::factor] = self._strided_mask[::factor, ::factor]\n",
    "        if self._roi_masking:\n",
    "            self._strided_mask = ones_mask*self._mask   \n",
    "            # self._strided_mask = ones_mask*self._largest_bbox_mask   \n",
    "            # self._strided_mask = ones_mask*self._all_bbox_mask \n",
    "            # self._strided_mask = self._all_strided_bbox_mask  \n",
    "        else:\n",
    "            self._strided_mask = ones_mask  \n",
    "        # print (np.count_nonzero(self._strided_mask), np.count_nonzero(self._mask[::factor, ::factor]))\n",
    "        # imshow(self._strided_mask.T, self._mask[::factor, ::factor].T)\n",
    "        # imshow(self._mask.T, self._strided_mask.T)\n",
    " \n",
    "        self._X_idcs, self._Y_idcs = np.where(self._strided_mask)        \n",
    "        self._idcs_num = len(self._X_idcs)\n",
    "\n",
    "    def __len__(self):        \n",
    "        return self._idcs_num \n",
    "\n",
    "    def save_get_mask(self, save_path):\n",
    "        np.save(save_path, self._mask)\n",
    "\n",
    "    def get_mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    def get_strided_mask(self):\n",
    "        return self._strided_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_coord, y_coord = self._X_idcs[idx], self._Y_idcs[idx]\n",
    "\n",
    "        # x = int(x_coord * self._resolution)\n",
    "        # y = int(y_coord * self._resolution)    \n",
    "\n",
    "        x = int(x_coord * self._resolution - self._image_size//2)\n",
    "        y = int(y_coord * self._resolution - self._image_size//2)    \n",
    "\n",
    "        img = self._slide.read_region(\n",
    "            (x, y), 0, (self._image_size, self._image_size)).convert('RGB')\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            label_img = self._label_slide.read_region(\n",
    "                (x, y), 0, (self._image_size, self._image_size)).convert('L')\n",
    "        else:\n",
    "            label_img = Image.fromarray(np.zeros((self._image_size, self._image_size), dtype=np.uint8))\n",
    "        \n",
    "        if self._flip == 'FLIP_LEFT_RIGHT':\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            label_img = label_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "        if self._rotate == 'ROTATE_90':\n",
    "            img = img.transpose(Image.ROTATE_90)\n",
    "            label_img = label_img.transpose(Image.ROTATE_90)\n",
    "            \n",
    "        if self._rotate == 'ROTATE_180':\n",
    "            img = img.transpose(Image.ROTATE_180)\n",
    "            label_img = label_img.transpose(Image.ROTATE_180)\n",
    "\n",
    "        if self._rotate == 'ROTATE_270':\n",
    "            img = img.transpose(Image.ROTATE_270)\n",
    "            label_img = label_img.transpose(Image.ROTATE_270)\n",
    "\n",
    "        # PIL image:   H x W x C\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        label_img = np.array(label_img, dtype=np.uint8)\n",
    "\n",
    "        if self._normalize:\n",
    "            img = (img - 128.0)/128.0\n",
    "   \n",
    "        return (img, x_coord, y_coord, label_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
