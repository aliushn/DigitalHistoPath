{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T08:27:05.721715Z",
     "start_time": "2019-09-07T08:27:03.593164Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import openslide\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, concatenate, Concatenate, UpSampling2D, Activation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms  # noqa\n",
    "\n",
    "import sklearn.metrics\n",
    "import io\n",
    "import itertools\n",
    "from six.moves import range\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "from models.seg_models import get_inception_resnet_v2_unet_softmax, unet_densenet121\n",
    "from models.deeplabv3p_original import Deeplabv3\n",
    "# Random Seeds\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "import tifffile \n",
    "import skimage.io as io\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T09:46:29.016998Z",
     "start_time": "2019-09-07T09:46:28.931029Z"
    }
   },
   "outputs": [],
   "source": [
    "# In[50]:\n",
    "\n",
    "\n",
    "# Image Helper Functions\n",
    "def imsave(*args, **kwargs):\n",
    "     \"\"\"\n",
    "     Concatenate the images given in args and saves them as a single image in the specified output destination.\n",
    "     Images should be numpy arrays and have same dimensions along the 0 axis.\n",
    "     imsave(im1,im2,out=\"sample.png\")\n",
    "     \"\"\"\n",
    "     args_list = list(args)\n",
    "     for i in range(len(args_list)):\n",
    "         if type(args_list[i]) != np.ndarray:\n",
    "             print(\"Not a numpy array\")\n",
    "             return 0\n",
    "         if len(args_list[i].shape) == 2:\n",
    "             args_list[i] = np.dstack([args_list[i]]*3)\n",
    "             if args_list[i].max() == 1:\n",
    "                args_list[i] = args_list[i]*255\n",
    "\n",
    "     out_destination = kwargs.get(\"out\",'')\n",
    "     try:\n",
    "         concatenated_arr = np.concatenate(args_list,axis=1)\n",
    "         im = Image.fromarray(np.uint8(concatenated_arr))\n",
    "     except Exception as e:\n",
    "         print(e)\n",
    "         import ipdb; ipdb.set_trace()\n",
    "         return 0\n",
    "     if out_destination:\n",
    "         print(f\"Saving to {out_destination}\")\n",
    "         im.save(out_destination)\n",
    "     else:\n",
    "        return im\n",
    "\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage:\n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    axis_off = kwargs.get('axis_off','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "            if axis_off: \n",
    "              plt.axis('off')  \n",
    "    plt.show()\n",
    "def normalize_minmax(data):\n",
    "    \"\"\"\n",
    "    Normalize contrast across volume\n",
    "    \"\"\"\n",
    "    _min = np.float(np.min(data))\n",
    "    _max = np.float(np.max(data))\n",
    "    if (_max-_min)!=0:\n",
    "        img = (data - _min) / (_max-_min)\n",
    "    else:\n",
    "        img = np.zeros_like(data)            \n",
    "    return img\n",
    "\n",
    "# Functions\n",
    "def BinMorphoProcessMask(mask,level):\n",
    "    \"\"\"\n",
    "    Binary operation performed on tissue mask\n",
    "    \"\"\"\n",
    "    close_kernel = np.ones((20, 20), dtype=np.uint8)\n",
    "    image_close = cv2.morphologyEx(np.array(mask), cv2.MORPH_CLOSE, close_kernel)\n",
    "    open_kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "    image_open = cv2.morphologyEx(np.array(image_close), cv2.MORPH_OPEN, open_kernel)\n",
    "    print(level)\n",
    "    if level == 2:\n",
    "        kernel = np.ones((100, 100), dtype=np.uint8)\n",
    "    elif level == 3:\n",
    "        kernel = np.ones((50, 50), dtype=np.uint8)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    image = cv2.dilate(image_open,kernel,iterations = 1)\n",
    "    return image\n",
    "\n",
    "def get_bbox(cont_img, rgb_image=None):\n",
    "    temp_img = np.uint8(cont_img.copy())\n",
    "    _,contours, _ = cv2.findContours(temp_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rgb_contour = None\n",
    "    if rgb_image is not None:\n",
    "        rgb_contour = rgb_image.copy()\n",
    "        line_color = (0, 0, 255)  # blue color code\n",
    "        cv2.drawContours(rgb_contour, contours, -1, line_color, 2)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        rgb_contour = cv2.rectangle(rgb_contour,(x,y),(x+h,y+w),(0,255,0),2)\n",
    "    return bounding_boxes, rgb_contour\n",
    "\n",
    "def get_all_bbox_masks(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the bbox and corresponding masks\n",
    "    \"\"\"\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    bounding_boxes, _ = get_bbox(mask)\n",
    "    y_size, x_size = bbox_mask.shape\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        x_min = x - stride_factor\n",
    "        x_max = x + h + stride_factor\n",
    "        y_min = y - stride_factor\n",
    "        y_max = y + w + stride_factor\n",
    "        if x_min < 0: \n",
    "         x_min = 0\n",
    "        if y_min < 0: \n",
    "         y_min = 0\n",
    "        if x_max > x_size: \n",
    "         x_max = x_size - 1\n",
    "        if y_max > y_size: \n",
    "         y_max = y_size - 1      \n",
    "        bbox_mask[y_min:y_max, x_min:x_max]=1\n",
    "    return bbox_mask\n",
    "\n",
    "def get_all_bbox_masks_with_stride(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the bbox and corresponding masks\n",
    "    \"\"\"\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    bounding_boxes, _ = get_bbox(mask)\n",
    "    y_size, x_size = bbox_mask.shape\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        x_min = x - stride_factor\n",
    "        x_max = x + h + stride_factor\n",
    "        y_min = y - stride_factor\n",
    "        y_max = y + w + stride_factor\n",
    "        if x_min < 0: \n",
    "         x_min = 0\n",
    "        if y_min < 0: \n",
    "         y_min = 0\n",
    "        if x_max > x_size: \n",
    "         x_max = x_size - 1\n",
    "        if y_max > y_size: \n",
    "         y_max = y_size - 1      \n",
    "        bbox_mask[y_min:y_max:stride_factor, x_min:x_max:stride_factor]=1\n",
    "        \n",
    "    return bbox_mask\n",
    "\n",
    "def find_largest_bbox(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the largest bounding box encompassing all the blobs\n",
    "    \"\"\"\n",
    "    y_size, x_size = mask.shape\n",
    "    x, y = np.where(mask==1)\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    x_min = np.min(x) - stride_factor\n",
    "    x_max = np.max(x) + stride_factor\n",
    "    y_min = np.min(y) - stride_factor\n",
    "    y_max = np.max(y) + stride_factor\n",
    "    \n",
    "    if x_min < 0: \n",
    "     x_min = 0\n",
    "    \n",
    "    if y_min < 0: \n",
    "     y_min = 0\n",
    "\n",
    "    if x_max > x_size: \n",
    "     x_max = x_size - 1\n",
    "    \n",
    "    if y_min > y_size: \n",
    "     y_max = y_size - 1    \n",
    "    \n",
    "    bbox_mask[x_min:x_max, y_min:y_max]=1\n",
    "    return bbox_mask\n",
    "    \n",
    "    \n",
    "def TissueMaskGeneration(slide_obj, level, RGB_min=50):\n",
    "    img_RGB = slide_obj.read_region((0, 0),level,slide_obj.level_dimensions[level])\n",
    "    img_RGB = np.transpose(np.array(img_RGB.convert('RGB')),axes=[1,0,2])\n",
    "    img_HSV = rgb2hsv(img_RGB)\n",
    "    background_R = img_RGB[:, :, 0] > threshold_otsu(img_RGB[:, :, 0])\n",
    "    background_G = img_RGB[:, :, 1] > threshold_otsu(img_RGB[:, :, 1])\n",
    "    background_B = img_RGB[:, :, 2] > threshold_otsu(img_RGB[:, :, 2])\n",
    "    tissue_RGB = np.logical_not(background_R & background_G & background_B)\n",
    "    tissue_S = img_HSV[:, :, 1] > threshold_otsu(img_HSV[:, :, 1])\n",
    "    min_R = img_RGB[:, :, 0] > RGB_min\n",
    "    min_G = img_RGB[:, :, 1] > RGB_min\n",
    "    min_B = img_RGB[:, :, 2] > RGB_min\n",
    "\n",
    "    tissue_mask = tissue_S & tissue_RGB & min_R & min_G & min_B\n",
    "    # r = img_RGB[:,:,0] < 235\n",
    "    # g = img_RGB[:,:,1] < 210\n",
    "    # b = img_RGB[:,:,2] < 235\n",
    "    # tissue_mask = np.logical_or(r,np.logical_or(g,b))\n",
    "    return tissue_mask \n",
    "\n",
    "def TissueMaskGenerationNew(slide_obj, level, RGB_min=50):\n",
    "     img_RGB = np.transpose(np.array(slide_obj.read_region((0, 0),\n",
    "                        level,\n",
    "                        slide_obj.level_dimensions[level]).convert('RGB')),\n",
    "                        axes=[1, 0, 2])\n",
    "     img_data = img_RGB.copy()\n",
    "     morpho_kernel = np.ones((7,7),np.uint8)\n",
    "     np.place(img_RGB, img_RGB<=0, 255)\n",
    "     img_RGB = cv2.medianBlur(img_RGB, 15)\n",
    "     img_HSV = rgb2hsv(img_RGB)\n",
    "     background_R = img_RGB[:, :, 0] > threshold_otsu(img_RGB[:, :, 0])\n",
    "     background_R = cv2.dilate(np.uint8(background_R), morpho_kernel, iterations = 5)\n",
    "     background_R = cv2.erode(np.uint8(background_R), morpho_kernel, iterations = 10)\n",
    "\n",
    "     background_G = img_RGB[:, :, 1] > threshold_otsu(img_RGB[:, :, 1])\n",
    "     background_G = cv2.dilate(np.uint8(background_G), morpho_kernel, iterations = 5)\n",
    "     background_G = cv2.erode(np.uint8(background_G), morpho_kernel, iterations = 10)\n",
    "\n",
    "     background_B = img_RGB[:, :, 2] > threshold_otsu(img_RGB[:, :, 2])\n",
    "     background_B = cv2.dilate(np.uint8(background_R), morpho_kernel, iterations = 5)\n",
    "     background_B = cv2.erode(np.uint8(background_B), morpho_kernel, iterations = 10)\n",
    "\n",
    "     tissue_RGB = np.logical_not(background_R & background_G & background_B)\n",
    "     tissue_S = img_HSV[:, :, 1] > threshold_otsu(img_HSV[:, :, 1])\n",
    "     min_R = img_RGB[:, :, 0] > RGB_min\n",
    "     min_G = img_RGB[:, :, 1] > RGB_min\n",
    "     min_B = img_RGB[:, :, 2] > RGB_min\n",
    "     tissue_mask = tissue_S & tissue_RGB & min_R & min_G & min_B\n",
    "     return tissue_mask\n",
    "\n",
    "def TissueMaskGenerationPatch(patchRGB):\n",
    "    '''\n",
    "    Returns mask of tissue that obeys the threshold set by paip\n",
    "    '''\n",
    "    r = patchRGB[:,:,0] < 235\n",
    "    g = patchRGB[:,:,1] < 210\n",
    "    b = patchRGB[:,:,2] < 235\n",
    "    tissue_mask = np.logical_or(r,np.logical_or(g,b))\n",
    "    return tissue_mask \n",
    "    \n",
    "def TissueMaskGeneration_BIN(slide_obj, level):\n",
    "    img_RGB = np.transpose(np.array(slide_obj.read_region((0, 0),\n",
    "                       level,\n",
    "                       slide_obj.level_dimensions[level]).convert('RGB')),\n",
    "                       axes=[1, 0, 2])    \n",
    "    img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2HSV)\n",
    "    img_S = img_HSV[:, :, 1]\n",
    "    _,tissue_mask = cv2.threshold(img_S, 0, 255, cv2.THRESH_BINARY)\n",
    "    return np.array(tissue_mask)\n",
    "\n",
    "def TissueMaskGeneration_BIN_OTSU(slide_obj, level):\n",
    "    img_RGB = np.transpose(np.array(slide_obj.read_region((0, 0),\n",
    "                       level,\n",
    "                       slide_obj.level_dimensions[level]).convert('RGB')),\n",
    "                       axes=[1, 0, 2])    \n",
    "    img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2HSV)\n",
    "    img_S = img_HSV[:, :, 1]\n",
    "    _,tissue_mask = cv2.threshold(img_S, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return np.array(tissue_mask)\n",
    "\n",
    "def labelthreshold(image, threshold=0.5):\n",
    "    np.place(image,image>=threshold, 1)\n",
    "    np.place(image,image<threshold, 0)\n",
    "    return np.uint8(image)\n",
    "\n",
    "def calc_jacc_score(x,y,smoothing=1):\n",
    "    for var in [x,y]:\n",
    "        np.place(var,var==255,1)\n",
    "    \n",
    "    numerator = np.sum(x*y)\n",
    "    denominator = np.sum(np.logical_or(x,y))\n",
    "    return (numerator+smoothing)/(denominator+smoothing)\n",
    "\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "# DataLoader Implementation\n",
    "class WSIStridedPatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Data producer that generate all the square grids, e.g. 3x3, of patches,\n",
    "    from a WSI and its tissue mask, and their corresponding indices with\n",
    "    respect to the tissue mask\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_path, mask_path, label_path=None, image_size=256,\n",
    "                 normalize=True, flip='NONE', rotate='NONE',                \n",
    "                 level=5, sampling_stride=16, roi_masking=True):\n",
    "        \"\"\"\n",
    "        Initialize the data producer.\n",
    "\n",
    "        Arguments:\n",
    "            wsi_path: string, path to WSI file\n",
    "            mask_path: string, path to mask file in numpy format OR None\n",
    "            label_mask_path: string, path to ground-truth label mask path in tif file or\n",
    "                            None (incase of Normal WSI or test-time)\n",
    "            image_size: int, size of the image before splitting into grid, e.g. 768\n",
    "            patch_size: int, size of the patch, e.g. 256\n",
    "            crop_size: int, size of the final crop that is feed into a CNN,\n",
    "                e.g. 224 for ResNet\n",
    "            normalize: bool, if normalize the [0, 255] pixel values to [-1, 1],\n",
    "                mostly False for debuging purpose\n",
    "            flip: string, 'NONE' or 'FLIP_LEFT_RIGHT' indicating the flip type\n",
    "            rotate: string, 'NONE' or 'ROTATE_90' or 'ROTATE_180' or\n",
    "                'ROTATE_270', indicating the rotate type\n",
    "            level: Level to extract the WSI tissue mask\n",
    "            roi_masking: True: Multiplies the strided WSI with tissue mask to eliminate white spaces,\n",
    "                                False: Ensures inference is done on the entire WSI   \n",
    "            sampling_stride: Number of pixels to skip in the tissue mask, basically it's the overlap\n",
    "                            fraction when patches are extracted from WSI during inference.\n",
    "                            stride=1 -> consecutive pixels are utilized\n",
    "                            stride= image_size/pow(2, level) -> non-overalaping patches \n",
    "        \"\"\"\n",
    "        self._wsi_path = wsi_path\n",
    "        self._mask_path = mask_path\n",
    "        self._label_path = label_path\n",
    "        self._image_size = image_size\n",
    "        self._normalize = normalize\n",
    "        self._flip = flip\n",
    "        self._rotate = rotate\n",
    "        self._level = level\n",
    "        self._sampling_stride = sampling_stride\n",
    "        self._roi_masking = roi_masking\n",
    "        \n",
    "        self._preprocess()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self._slide = openslide.OpenSlide(self._wsi_path)\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            self._label_slide = openslide.OpenSlide(self._label_path)\n",
    "        \n",
    "        X_slide, Y_slide = self._slide.level_dimensions[0]\n",
    "        print(\"Image dimensions: (%d,%d)\" %(X_slide,Y_slide))\n",
    "        \n",
    "        factor = self._sampling_stride\n",
    "\n",
    "        \n",
    "        if self._mask_path is not None:\n",
    "            mask_file_name = os.path.basename(self._mask_path)\n",
    "            if mask_file_name.endswith('.tiff'):\n",
    "                mask_obj = openslide.OpenSlide(self._mask_path)\n",
    "                self._mask = np.array(mask_obj.read_region((0, 0),\n",
    "                       self._level,\n",
    "                       mask_obj.level_dimensions[self._level]).convert('L')).T\n",
    "                np.place(self._mask,self._mask>0,255)\n",
    "        else:\n",
    "            # Generate tissue mask on the fly    \n",
    "            \n",
    "            self._mask = TissueMaskGeneration(self._slide, self._level)\n",
    "        # morphological operations ensure the holes are filled in tissue mask\n",
    "        # and minor points are aggregated to form a larger chunk         \n",
    "\n",
    "        self._mask = BinMorphoProcessMask(np.uint8(self._mask),self._level)\n",
    "        # self._all_bbox_mask = get_all_bbox_masks(self._mask, factor)\n",
    "        # self._largest_bbox_mask = find_largest_bbox(self._mask, factor)\n",
    "        # self._all_strided_bbox_mask = get_all_bbox_masks_with_stride(self._mask, factor)\n",
    "\n",
    "        X_mask, Y_mask = self._mask.shape\n",
    "        # print (self._mask.shape, np.where(self._mask>0))\n",
    "        # imshow(self._mask.T)\n",
    "        # cm17 dataset had issues with images being power's of 2 precisely        \n",
    "#         if X_slide != X_mask or Y_slide != Y_mask:\n",
    "        print('Mask (%d,%d) and Slide(%d,%d) '%(X_mask,Y_mask,X_slide,Y_slide))\n",
    "        if X_slide // X_mask != Y_slide // Y_mask:\n",
    "            raise Exception('Slide/Mask dimension does not match ,'\n",
    "                            ' X_slide / X_mask : {} / {},'\n",
    "                            ' Y_slide / Y_mask : {} / {}'\n",
    "                            .format(X_slide, X_mask, Y_slide, Y_mask))\n",
    "\n",
    "        self._resolution = np.round(X_slide * 1.0 / X_mask)\n",
    "        if not np.log2(self._resolution).is_integer():\n",
    "            raise Exception('Resolution (X_slide / X_mask) is not power of 2 :'\n",
    "                            ' {}'.format(self._resolution))\n",
    "             \n",
    "        # all the idces for tissue region from the tissue mask  \n",
    "        self._strided_mask =  np.ones_like(self._mask)\n",
    "        ones_mask = np.zeros_like(self._mask)\n",
    "        ones_mask[::factor, ::factor] = self._strided_mask[::factor, ::factor]\n",
    "        \n",
    "        \n",
    "        if self._roi_masking:\n",
    "            self._strided_mask = ones_mask*self._mask   \n",
    "            # self._strided_mask = ones_mask*self._largest_bbox_mask   \n",
    "            # self._strided_mask = ones_mask*self._all_bbox_mask \n",
    "            # self._strided_mask = self._all_strided_bbox_mask  \n",
    "        else:\n",
    "            self._strided_mask = ones_mask  \n",
    "        # print (np.count_nonzero(self._strided_mask), np.count_nonzero(self._mask[::factor, ::factor]))\n",
    "        # imshow(self._strided_mask.T, self._mask[::factor, ::factor].T)\n",
    "        # imshow(self._mask.T, self._strided_mask.T)\n",
    " \n",
    "        self._X_idcs, self._Y_idcs = np.where(self._strided_mask)        \n",
    "        self._idcs_num = len(self._X_idcs)\n",
    "\n",
    "    def __len__(self):        \n",
    "        return self._idcs_num \n",
    "\n",
    "    def save_scaled_imgs(self):\n",
    "        scld_dms = self._slide.level_dimensions[self._level]\n",
    "        self._slide_scaled = self._slide.read_region((0,0),self._level,scld_dms)\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            self._label_scaled = np.array(self._label_slide.read_region((0,0),4,scld_dms).convert('L'))\n",
    "            np.place(self._label_scaled,self._label_scaled>0,255)\n",
    "        \n",
    "    def save_get_mask(self, save_path):\n",
    "        np.save(save_path, self._mask)\n",
    "\n",
    "    def get_mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    def get_strided_mask(self):\n",
    "        return self._strided_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_coord, y_coord = self._X_idcs[idx], self._Y_idcs[idx]\n",
    "        \n",
    "        x_max_dim,y_max_dim = self._slide.level_dimensions[0]\n",
    "\n",
    "        # x = int(x_coord * self._resolution)\n",
    "        # y = int(y_coord * self._resolution)    \n",
    "\n",
    "        x = int(x_coord * self._resolution - self._image_size//2)\n",
    "        y = int(y_coord * self._resolution - self._image_size//2)    \n",
    "#         x = int(x_coord * self._resolution)\n",
    "#         y = int(y_coord * self._resolution)    \n",
    "        \n",
    "        #If Image goes out of bounds\n",
    "        if x>(x_max_dim - image_size):\n",
    "            x = x_max_dim - image_size\n",
    "        elif x<0:\n",
    "            x = 0\n",
    "        if y>(y_max_dim - image_size):\n",
    "            y = y_max_dim - image_size\n",
    "        elif y<0:\n",
    "            y = 0\n",
    "    \n",
    "        #Converting pil image to np array transposes the w and h\n",
    "        img = np.transpose(self._slide.read_region(\n",
    "            (x, y), 0, (self._image_size, self._image_size)).convert('RGB'),[1,0,2])\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            label_img = self._label_slide.read_region(\n",
    "                (x, y), 0, (self._image_size, self._image_size)).convert('L')\n",
    "        else:\n",
    "            #print('No label img')\n",
    "            label_img = Image.fromarray(np.zeros((self._image_size, self._image_size), dtype=np.uint8))\n",
    "        \n",
    "        if self._flip == 'FLIP_LEFT_RIGHT':\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            label_img = label_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "        if self._rotate == 'ROTATE_90':\n",
    "            img = img.transpose(Image.ROTATE_90)\n",
    "            label_img = label_img.transpose(Image.ROTATE_90)\n",
    "            \n",
    "        if self._rotate == 'ROTATE_180':\n",
    "            img = img.transpose(Image.ROTATE_180)\n",
    "            label_img = label_img.transpose(Image.ROTATE_180)\n",
    "\n",
    "        if self._rotate == 'ROTATE_270':\n",
    "            img = img.transpose(Image.ROTATE_270)\n",
    "            label_img = label_img.transpose(Image.ROTATE_270)\n",
    "\n",
    "        # PIL image:   H x W x C\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        label_img = np.array(label_img, dtype=np.uint8)\n",
    "        np.place(label_img, label_img>0, 255)\n",
    "\n",
    "        if self._normalize:\n",
    "            img = (img - 128.0)/128.0\n",
    "   \n",
    "        return (img, x, y, label_img)\n",
    "#CONF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T09:59:37.954677Z",
     "start_time": "2019-09-07T09:58:22.132742Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_size = 1024\n",
    "sampling_stride = 512\n",
    "batch_size = 1\n",
    "wsi_paths = glob.glob('../../data/raw-data/test/1[5-7][0-3].svs')[1:]\n",
    "print(\"Total %d\" %len(wsi_paths))\n",
    "for i,wsi_path in enumerate(wsi_paths):\n",
    "    print(i,'/', len(wsi_paths),wsi_path)\n",
    "    label_path=None\n",
    "    wsi_obj = openslide.OpenSlide(wsi_path)\n",
    "    x_max_dim,y_max_dim = wsi_obj.level_dimensions[0]\n",
    "    scld_dms = wsi_obj.level_dimensions[2]\n",
    "    \n",
    "    if len(wsi_obj.level_dimensions) == 3:\n",
    "        level = 2\n",
    "    elif len(wsi_obj.level_dimensions) ==4 :\n",
    "        level = 3\n",
    "        \n",
    "    \n",
    "    scale = lambda x: cv2.resize(x,tuple(reversed(scld_dms))).T\n",
    "    mask_path = None\n",
    "    start_time = time.time()\n",
    "    dataset_obj = WSIStridedPatchDataset(wsi_path, \n",
    "                                        mask_path,\n",
    "                                        label_path,\n",
    "                                        image_size=image_size,\n",
    "                                        normalize=True,\n",
    "                                        flip=None, rotate=None,\n",
    "                                        level=level, sampling_stride=sampling_stride//16, roi_masking=True)\n",
    "\n",
    "    dataloader = DataLoader(dataset_obj, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "    dataset_obj.save_scaled_imgs()\n",
    "    out_file = wsi_path.split('/')[-1].split('.')[0]\n",
    "    # out_file = sample_id\n",
    "\n",
    "    print(dataset_obj.get_mask().shape)\n",
    "    st_im = dataset_obj.get_strided_mask()\n",
    "    mask_im = np.dstack([dataset_obj.get_mask().T]*3).astype('uint8')*255\n",
    "    st_im = np.dstack([dataset_obj.get_strided_mask().T]*3).astype('uint8')*255\n",
    "    im_im = np.array(dataset_obj._slide_scaled.convert('RGB'))\n",
    "    ov_im = st_im/2 + im_im/2\n",
    "    ov_im_mask= mask_im/2 + im_im/2\n",
    "    out_file = os.path.join('../../results/saved_images/test_mask_ref','ref_'+out_file)+'.png'\n",
    "    display(imsave(ov_im_mask.astype('uint8'),(im_im)))\n",
    "    display(imsave(ov_im.astype('uint8')))\n",
    "    if i >10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T08:09:42.622074Z",
     "start_time": "2019-09-07T07:58:19.858319Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "import itertools\n",
    "\n",
    "print(wsi_obj.level_dimensions)\n",
    "scld_dms = wsi_obj.level_dimensions[2]\n",
    "scaled_img = np.zeros(scld_dms+(3,)).astype('uint8')\n",
    "print(scaled_img.shape)\n",
    "image_size = 1024*2 \n",
    "scale = 16\n",
    "xes = list(range(scld_dms[0]*scale//image_size))\n",
    "ys = list(range(scld_dms[1]*scale//image_size))\n",
    "for (x,y) in itertools.product(xes,ys):\n",
    "    full_x = x*(image_size)\n",
    "    full_y = y*(image_size)\n",
    "    scale_x = x*(image_size)//scale\n",
    "    scale_y = y*(image_size)//scale\n",
    "    full_img_patch = np.array(wsi_obj.read_region((full_x,full_y),0,(image_size,image_size)).convert('RGB'))\n",
    "    scaled_img_patch = block_reduce(full_img_patch,block_size=(scale,scale,1),func=np.mean).astype('uint8')\n",
    "    scaled_img[scale_x:scale_x+image_size//scale,scale_y:scale_y+image_size//scale,:] = scaled_img_patch\n",
    "#     print(full_x,full_y)\n",
    "#     print(scale_x,scale_y)\n",
    "#     print('-'*10)\n",
    "    if x%10==0 and y%40==0:\n",
    "        print(\"%d/%d , %d/%d \" %(x,len(xes),y,len(ys)))\n",
    "        imshow(scaled_img)\n",
    "    if x==50 and y==10:\n",
    "         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T09:36:45.187632Z",
     "start_time": "2019-09-07T09:36:44.842594Z"
    }
   },
   "outputs": [],
   "source": [
    "wsi_obj = openslide.OpenSlide('../../data/raw-data/test/175.svs')\n",
    "wsi_obj.read_region((0,0),3,wsi_obj.level_dimensions[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T09:34:10.761369Z",
     "start_time": "2019-09-07T09:34:10.316796Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyvips\n",
    "a=pyvips.Image.openslideload('../../data/raw-data/test/173.svs',level=3)\n",
    "b = np.ndarray(buffer=a.write_to_memory(),dtype='uint8',shape=[a.height, a.width, a.bands])\n",
    "Image.fromarray(b)\n",
    "# imshow(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
