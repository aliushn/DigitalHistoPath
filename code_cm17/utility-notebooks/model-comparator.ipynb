{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T07:03:41.620135Z",
     "start_time": "2019-08-27T07:03:41.240001Z"
    }
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# import imgaug\n",
    "# from imgaug import augmenters as iaa\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import openslide\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, concatenate, Concatenate, UpSampling2D, Activation\n",
    "# from tensorflow.keras.losses import categorical_crossentropy\n",
    "# from tensorflow.keras.applications.densenet import DenseNet121\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "# from tensorflow.keras import metrics\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms  # noqa\n",
    "\n",
    "import sklearn.metrics\n",
    "import io\n",
    "import itertools\n",
    "from six.moves import range\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "from models.seg_models import unet_densenet121, get_inception_resnet_v2_unet_softmax\n",
    "# Random Seeds\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "# import tifffile \n",
    "# import skimage.io as io\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_labels, unary_from_softmax\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n",
    "    create_pairwise_gaussian\n",
    "\n",
    "# Fully connected CRF post processing function\n",
    "def do_crf(im, mask, zero_unsure=True):\n",
    "    colors, labels = np.unique(mask, return_inverse=True)\n",
    "    image_size = mask.shape[:2]\n",
    "    n_labels = len(set(labels.flat))\n",
    "    d = dcrf.DenseCRF2D(image_size[1], image_size[0], n_labels)  # width, height, nlabels\n",
    "    U = unary_from_labels(labels, n_labels, gt_prob=.7, zero_unsure=zero_unsure)\n",
    "    d.setUnaryEnergy(U)\n",
    "    # This adds the color-independent term, features are the locations only.\n",
    "    d.addPairwiseGaussian(sxy=(3,3), compat=3)\n",
    "    # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "    # im is an image-array, e.g. im.dtype == np.uint8 and im.shape == (640,480,3)\n",
    "    d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=im.astype('uint8'), compat=10)\n",
    "    Q = d.inference(5) # 5 - num of iterations\n",
    "    MAP = np.argmax(Q, axis=0).reshape(image_size)\n",
    "    unique_map = np.unique(MAP)\n",
    "    for u in unique_map: # get original labels back\n",
    "        np.putmask(MAP, MAP == u, colors[u])\n",
    "    return MAP\n",
    "    # MAP = do_crf(frame, labels.astype('int32'), zero_unsure=False)\n",
    "\n",
    "\n",
    "def post_process_crf(image, final_probabilities, num_cl):\n",
    "    softmax = final_probabilities.squeeze()\n",
    "    softmax = softmax.transpose((2, 0, 1))\n",
    "\n",
    "    # The input should be the negative of the logarithm of probability values\n",
    "    # Look up the definition of the unary_from_softmax for more information\n",
    "    unary = unary_from_softmax(softmax, scale=None, clip=1e-5)\n",
    "\n",
    "    # The inputs should be C-continious -- we are using Cython wrapper\n",
    "    unary = np.ascontiguousarray(unary)\n",
    "\n",
    "    d = dcrf.DenseCRF(image.shape[0] * image.shape[1], num_cl)\n",
    "\n",
    "    d.setUnaryEnergy(unary)\n",
    "\n",
    "    # This potential penalizes small pieces of segmentation that are\n",
    "    # spatially isolated -- enforces more spatially consistent segmentations\n",
    "    feats = create_pairwise_gaussian(sdims=(10, 10), shape=image.shape[:2])\n",
    "\n",
    "    d.addPairwiseEnergy(feats, compat=3,\n",
    "                        kernel=dcrf.DIAG_KERNEL,\n",
    "                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    # This creates the color-dependent features --\n",
    "    # because the segmentation that we get from CNN are too coarse\n",
    "    # and we can use local color features to refine them\n",
    "    feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n",
    "                                    img=image, chdim=2)\n",
    "\n",
    "    d.addPairwiseEnergy(feats, compat=10,\n",
    "                        kernel=dcrf.DIAG_KERNEL,\n",
    "                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    Q = d.inference(10)\n",
    "    res = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
    "\n",
    "    return res \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T22:38:21.143445Z",
     "start_time": "2019-08-26T22:38:20.984877Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Image Helper Functions\n",
    "def imsave(*args, **kwargs):\n",
    "     \"\"\"\n",
    "     Concatenate the images given in args and saves them as a single image in the specified output destination.\n",
    "     Images should be numpy arrays and have same dimensions along the 0 axis.\n",
    "     imsave(im1,im2,out=\"sample.png\")\n",
    "     \"\"\"\n",
    "     args_list = list(args)\n",
    "     for i in range(len(args_list)):\n",
    "         if type(args_list[i]) != np.ndarray:\n",
    "             print(\"Not a numpy array\")\n",
    "             return 0\n",
    "         if len(args_list[i].shape) == 2:\n",
    "             args_list[i] = np.dstack([args_list[i]]*3)\n",
    "             if args_list[i].max() == 1:\n",
    "                args_list[i] = args_list[i]*255\n",
    "\n",
    "     out_destination = kwargs.get(\"out\",'')\n",
    "     try:\n",
    "         concatenated_arr = np.concatenate(args_list,axis=1)\n",
    "         im = Image.fromarray(np.uint8(concatenated_arr))\n",
    "     except Exception as e:\n",
    "         print(e)\n",
    "         import ipdb; ipdb.set_trace()\n",
    "         return 0\n",
    "     if out_destination:\n",
    "         print(\"Saving to %s\" % out_destination)\n",
    "         im.save(out_destination)\n",
    "     else:\n",
    "        return im\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage:\n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    axis_off = kwargs.get('axis_off','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "            if axis_off: \n",
    "              plt.axis('off')  \n",
    "    plt.show()\n",
    "def normalize_minmax(data):\n",
    "    \"\"\"\n",
    "    Normalize contrast across volume\n",
    "    \"\"\"\n",
    "    _min = np.float(np.min(data))\n",
    "    _max = np.float(np.max(data))\n",
    "    if (_max-_min)!=0:\n",
    "        img = (data - _min) / (_max-_min)\n",
    "    else:\n",
    "        img = np.zeros_like(data)            \n",
    "    return img\n",
    "\n",
    "# Functions\n",
    "def BinMorphoProcessMask(mask):\n",
    "    \"\"\"\n",
    "    Binary operation performed on tissue mask\n",
    "    \"\"\"\n",
    "    close_kernel = np.ones((20, 20), dtype=np.uint8)\n",
    "    image_close = cv2.morphologyEx(np.array(mask), cv2.MORPH_CLOSE, close_kernel)\n",
    "    open_kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "    image_open = cv2.morphologyEx(np.array(image_close), cv2.MORPH_OPEN, open_kernel)\n",
    "    kernel = np.ones((20, 20), dtype=np.uint8)\n",
    "    image = cv2.dilate(image_open,kernel,iterations = 1)\n",
    "    return image\n",
    "def get_bbox(cont_img, rgb_image=None):\n",
    "    contours, _ = cv2.findContours(cont_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rgb_contour = None\n",
    "    if rgb_image is not None:\n",
    "        rgb_contour = rgb_image.copy()\n",
    "        line_color = (0, 0, 255)  # blue color code\n",
    "        cv2.drawContours(rgb_contour, contours, -1, line_color, 2)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        rgb_contour = cv2.rectangle(rgb_contour,(x,y),(x+h,y+w),(0,255,0),2)\n",
    "    return bounding_boxes, rgb_contour\n",
    "def get_all_bbox_masks(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the bbox and corresponding masks\n",
    "    \"\"\"\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    bounding_boxes, _ = get_bbox(mask)\n",
    "    y_size, x_size = bbox_mask.shape\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        x_min = x - stride_factor\n",
    "        x_max = x + h + stride_factor\n",
    "        y_min = y - stride_factor\n",
    "        y_max = y + w + stride_factor\n",
    "        if x_min < 0: \n",
    "         x_min = 0\n",
    "        if y_min < 0: \n",
    "         y_min = 0\n",
    "        if x_max > x_size: \n",
    "         x_max = x_size - 1\n",
    "        if y_max > y_size: \n",
    "         y_max = y_size - 1      \n",
    "        bbox_mask[y_min:y_max, x_min:x_max]=1\n",
    "    return bbox_mask\n",
    "def get_all_bbox_masks_with_stride(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the bbox and corresponding masks\n",
    "    \"\"\"\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    bounding_boxes, _ = get_bbox(mask)\n",
    "    y_size, x_size = bbox_mask.shape\n",
    "    for x, y, h, w in bounding_boxes:\n",
    "        x_min = x - stride_factor\n",
    "        x_max = x + h + stride_factor\n",
    "        y_min = y - stride_factor\n",
    "        y_max = y + w + stride_factor\n",
    "        if x_min < 0: \n",
    "         x_min = 0\n",
    "        if y_min < 0: \n",
    "         y_min = 0\n",
    "        if x_max > x_size: \n",
    "         x_max = x_size - 1\n",
    "        if y_max > y_size: \n",
    "         y_max = y_size - 1      \n",
    "        bbox_mask[y_min:y_max:stride_factor, x_min:x_max:stride_factor]=1\n",
    "        \n",
    "    return bbox_mask\n",
    "def find_largest_bbox(mask, stride_factor):\n",
    "    \"\"\"\n",
    "    Find the largest bounding box encompassing all the blobs\n",
    "    \"\"\"\n",
    "    y_size, x_size = mask.shape\n",
    "    x, y = np.where(mask==1)\n",
    "    bbox_mask = np.zeros_like(mask)\n",
    "    x_min = np.min(x) - stride_factor\n",
    "    x_max = np.max(x) + stride_factor\n",
    "    y_min = np.min(y) - stride_factor\n",
    "    y_max = np.max(y) + stride_factor\n",
    "    \n",
    "    if x_min < 0: \n",
    "     x_min = 0\n",
    "    \n",
    "    if y_min < 0: \n",
    "     y_min = 0\n",
    "\n",
    "    if x_max > x_size: \n",
    "     x_max = x_size - 1\n",
    "    \n",
    "    if y_min > y_size: \n",
    "     y_max = y_size - 1    \n",
    "    \n",
    "    bbox_mask[x_min:x_max, y_min:y_max]=1\n",
    "    return bbox_mask\n",
    "    \n",
    "def TissueMaskGeneration(slide_obj, level, RGB_min=50):\n",
    "    img_RGB = slide_obj.read_region((0, 0),level,slide_obj.level_dimensions[level])\n",
    "    img_RGB = np.transpose((img_RGB.convert('RGB')),axes=[1,0,2])\n",
    "    img_HSV = rgb2hsv(img_RGB)\n",
    "    background_R = img_RGB[:, :, 0] > threshold_otsu(img_RGB[:, :, 0])\n",
    "    background_G = img_RGB[:, :, 1] > threshold_otsu(img_RGB[:, :, 1])\n",
    "    background_B = img_RGB[:, :, 2] > threshold_otsu(img_RGB[:, :, 2])\n",
    "    tissue_RGB = np.logical_not(background_R & background_G & background_B)\n",
    "    tissue_S = img_HSV[:, :, 1] > threshold_otsu(img_HSV[:, :, 1])\n",
    "    min_R = img_RGB[:, :, 0] > RGB_min\n",
    "    min_G = img_RGB[:, :, 1] > RGB_min\n",
    "    min_B = img_RGB[:, :, 2] > RGB_min\n",
    "\n",
    "    tissue_mask = tissue_S & tissue_RGB & min_R & min_G & min_B\n",
    "    # r = img_RGB[:,:,0] < 235\n",
    "    # g = img_RGB[:,:,1] < 210\n",
    "    # b = img_RGB[:,:,2] < 235\n",
    "    # tissue_mask = np.logical_or(r,np.logical_or(g,b))\n",
    "    return tissue_mask \n",
    "def TissueMaskGenerationPatch(patchRGB):\n",
    "    '''\n",
    "    Returns mask of tissue that obeys the threshold set by paip\n",
    "    '''\n",
    "    r = patchRGB[:,:,0] < 235\n",
    "    g = patchRGB[:,:,1] < 210\n",
    "    b = patchRGB[:,:,2] < 235\n",
    "    tissue_mask = np.logical_or(r,np.logical_or(g,b))\n",
    "    return tissue_mask \n",
    "    \n",
    "def TissueMaskGeneration_BIN(slide_obj, level):\n",
    "    img_RGB = np.transpose(np.array(slide_obj.read_region((0, 0),\n",
    "                       level,\n",
    "                       slide_obj.level_dimensions[level]).convert('RGB')),\n",
    "                       axes=[1, 0, 2])    \n",
    "    img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2HSV)\n",
    "    img_S = img_HSV[:, :, 1]\n",
    "    _,tissue_mask = cv2.threshold(img_S, 0, 255, cv2.THRESH_BINARY)\n",
    "    return np.array(tissue_mask)\n",
    "\n",
    "def TissueMaskGeneration_BIN_OTSU(slide_obj, level):\n",
    "    img_RGB = np.transpose(np.array(slide_obj.read_region((0, 0),\n",
    "                       level,\n",
    "                       slide_obj.level_dimensions[level]).convert('RGB')),\n",
    "                       axes=[1, 0, 2])    \n",
    "    img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2HSV)\n",
    "    img_S = img_HSV[:, :, 1]\n",
    "    _,tissue_mask = cv2.threshold(img_S, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return np.array(tissue_mask)\n",
    "\n",
    "def labelthreshold(image, threshold=0.5):\n",
    "    label = np.zeros_like(image)\n",
    "    label[image>=threshold] = 1\n",
    "#     np.place(image,image>=threshold, 1)\n",
    "#     np.place(image,image<threshold, 0)\n",
    "    return np.uint8(label)\n",
    "\n",
    "def calc_jacc_score(x,y,smoothing=1):\n",
    "    for var in [x,y]:\n",
    "        np.place(var,var==255,1)\n",
    "    \n",
    "    numerator = np.sum(x*y)\n",
    "    denominator = np.sum(np.logical_or(x,y))\n",
    "    return (numerator+smoothing)/(denominator+smoothing)\n",
    "    \n",
    "\n",
    "def get_tumor_fraction(mask_image):\n",
    "    fraction = np.count_nonzero(mask_image)/np.prod(mask_image.shape)\n",
    "    return fraction\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# DataLoader Implementation\n",
    "class WSIStridedPatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Data producer that generate all the square grids, e.g. 3x3, of patches,\n",
    "    from a WSI and its tissue mask, and their corresponding indices with\n",
    "    respect to the tissue mask\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_path, mask_path, label_path=None, image_size=256,\n",
    "                 normalize=True, flip='NONE', rotate='NONE',                \n",
    "                 level=5, sampling_stride=16, roi_masking=True):\n",
    "        \"\"\"\n",
    "        Initialize the data producer.\n",
    "\n",
    "        Arguments:\n",
    "            wsi_path: string, path to WSI file\n",
    "            mask_path: string, path to mask file in numpy format OR None\n",
    "            label_mask_path: string, path to ground-truth label mask path in tif file or\n",
    "                            None (incase of Normal WSI or test-time)\n",
    "            image_size: int, size of the image before splitting into grid, e.g. 768\n",
    "            patch_size: int, size of the patch, e.g. 256\n",
    "            crop_size: int, size of the final crop that is feed into a CNN,\n",
    "                e.g. 224 for ResNet\n",
    "            normalize: bool, if normalize the [0, 255] pixel values to [-1, 1],\n",
    "                mostly False for debuging purpose\n",
    "            flip: string, 'NONE' or 'FLIP_LEFT_RIGHT' indicating the flip type\n",
    "            rotate: string, 'NONE' or 'ROTATE_90' or 'ROTATE_180' or\n",
    "                'ROTATE_270', indicating the rotate type\n",
    "            level: Level to extract the WSI tissue mask\n",
    "            roi_masking: True: Multiplies the strided WSI with tissue mask to eliminate white spaces,\n",
    "                                False: Ensures inference is done on the entire WSI   \n",
    "            sampling_stride: Number of pixels to skip in the tissue mask, basically it's the overlap\n",
    "                            fraction when patches are extracted from WSI during inference.\n",
    "                            stride=1 -> consecutive pixels are utilized\n",
    "                            stride= image_size/pow(2, level) -> non-overalaping patches \n",
    "        \"\"\"\n",
    "        self._wsi_path = wsi_path\n",
    "        self._mask_path = mask_path\n",
    "        self._label_path = label_path\n",
    "        self._image_size = image_size\n",
    "        self._normalize = normalize\n",
    "        self._flip = flip\n",
    "        self._rotate = rotate\n",
    "        self._level = level\n",
    "        self._sampling_stride = sampling_stride\n",
    "        self._roi_masking = roi_masking\n",
    "        \n",
    "        self._preprocess()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self._slide = openslide.OpenSlide(self._wsi_path)\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            self._label_slide = openslide.OpenSlide(self._label_path)\n",
    "        \n",
    "        X_slide, Y_slide = self._slide.level_dimensions[0]\n",
    "        print(\"Image dimensions: (%d,%d)\" %(X_slide,Y_slide))\n",
    "        \n",
    "        factor = self._sampling_stride\n",
    "\n",
    "        \n",
    "        if self._mask_path is not None:\n",
    "            mask_file_name = os.path.basename(self._mask_path)\n",
    "            if mask_file_name.endswith('.tiff'):\n",
    "                mask_obj = openslide.OpenSlide(self._mask_path)\n",
    "                self._mask = np.array(mask_obj.read_region((0, 0),\n",
    "                       self._level,\n",
    "                       mask_obj.level_dimensions[self._level]).convert('L')).T\n",
    "                np.place(self._mask,self._mask>0,255)\n",
    "        else:\n",
    "            # Generate tissue mask on the fly    \n",
    "            \n",
    "            self._mask = TissueMaskGeneration(self._slide, self._level)\n",
    "        # morphological operations ensure the holes are filled in tissue mask\n",
    "        # and minor points are aggregated to form a larger chunk         \n",
    "\n",
    "        self._mask = BinMorphoProcessMask(np.uint8(self._mask))\n",
    "        # self._all_bbox_mask = get_all_bbox_masks(self._mask, factor)\n",
    "        # self._largest_bbox_mask = find_largest_bbox(self._mask, factor)\n",
    "        # self._all_strided_bbox_mask = get_all_bbox_masks_with_stride(self._mask, factor)\n",
    "\n",
    "        X_mask, Y_mask = self._mask.shape\n",
    "        # print (self._mask.shape, np.where(self._mask>0))\n",
    "        # imshow(self._mask.T)\n",
    "        # cm17 dataset had issues with images being power's of 2 precisely        \n",
    "#         if X_slide != X_mask or Y_slide != Y_mask:\n",
    "        print('Mask (%d,%d) and Slide(%d,%d) '%(X_mask,Y_mask,X_slide,Y_slide))\n",
    "        if X_slide // X_mask != Y_slide // Y_mask:\n",
    "            raise Exception('Slide/Mask dimension does not match ,'\n",
    "                            ' X_slide / X_mask : {} / {},'\n",
    "                            ' Y_slide / Y_mask : {} / {}'\n",
    "                            .format(X_slide, X_mask, Y_slide, Y_mask))\n",
    "\n",
    "        self._resolution = np.round(X_slide * 1.0 / X_mask)\n",
    "        if not np.log2(self._resolution).is_integer():\n",
    "            raise Exception('Resolution (X_slide / X_mask) is not power of 2 :'\n",
    "                            ' {}'.format(self._resolution))\n",
    "             \n",
    "        # all the idces for tissue region from the tissue mask  \n",
    "        self._strided_mask =  np.ones_like(self._mask)\n",
    "        ones_mask = np.zeros_like(self._mask)\n",
    "        ones_mask[::factor, ::factor] = self._strided_mask[::factor, ::factor]\n",
    "        \n",
    "        \n",
    "        if self._roi_masking:\n",
    "            self._strided_mask = ones_mask*self._mask   \n",
    "            # self._strided_mask = ones_mask*self._largest_bbox_mask   \n",
    "            # self._strided_mask = ones_mask*self._all_bbox_mask \n",
    "            # self._strided_mask = self._all_strided_bbox_mask  \n",
    "        else:\n",
    "            self._strided_mask = ones_mask  \n",
    "        # print (np.count_nonzero(self._strided_mask), np.count_nonzero(self._mask[::factor, ::factor]))\n",
    "        # imshow(self._strided_mask.T, self._mask[::factor, ::factor].T)\n",
    "        # imshow(self._mask.T, self._strided_mask.T)\n",
    " \n",
    "        self._X_idcs, self._Y_idcs = np.where(self._strided_mask)        \n",
    "        self._idcs_num = len(self._X_idcs)\n",
    "\n",
    "    def __len__(self):        \n",
    "        return self._idcs_num \n",
    "\n",
    "    def save_scaled_imgs(self):\n",
    "        scld_dms = self._slide.level_dimensions[2]\n",
    "        self._slide_scld = np.transpose(self._slide.read_region((0,0),2,scld_dms).convert('RGB'),[1,0,2])\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            self._label_scld = np.array(self._label_slide.read_region((0,0),4,scld_dms).convert('L')).T\n",
    "            np.place(self._label_scld,self._label_scld>0,255)\n",
    "        \n",
    "    def save_get_mask(self, save_path):\n",
    "        np.save(save_path, self._mask)\n",
    "\n",
    "    def get_mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    def get_strided_mask(self):\n",
    "        return self._strided_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_coord, y_coord = self._X_idcs[idx], self._Y_idcs[idx]\n",
    "        \n",
    "        x_max_dim,y_max_dim = self._slide.level_dimensions[0]\n",
    "\n",
    "        # x = int(x_coord * self._resolution)\n",
    "        # y = int(y_coord * self._resolution)    \n",
    "\n",
    "        x = int(x_coord * self._resolution - self._image_size//2)\n",
    "        y = int(y_coord * self._resolution - self._image_size//2)    \n",
    "#         x = int(x_coord * self._resolution)\n",
    "#         y = int(y_coord * self._resolution)    \n",
    "        \n",
    "        #If Image goes out of bounds\n",
    "        if x>(x_max_dim - image_size):\n",
    "            x = x_max_dim - image_size\n",
    "        elif x<0:\n",
    "            x = 0\n",
    "        if y>(y_max_dim - image_size):\n",
    "            y = y_max_dim - image_size\n",
    "        elif y<0:\n",
    "            y = 0\n",
    "    \n",
    "        #Converting pil image to np array transposes the w and h\n",
    "        img = np.transpose(self._slide.read_region(\n",
    "            (x, y), 0, (self._image_size, self._image_size)).convert('RGB'),[1,0,2])\n",
    "        \n",
    "        if self._label_path is not None:\n",
    "            label_img = np.transpose(self._label_slide.read_region(\n",
    "                (x, y), 0, (self._image_size, self._image_size)).convert('L'),[1,0])\n",
    "        else:\n",
    "            #print('No label img')\n",
    "            label_img = np.transpose(Image.fromarray(np.zeros((self._image_size, self._image_size), dtype=np.uint8)))\n",
    "        \n",
    "        if self._flip == 'FLIP_LEFT_RIGHT':\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            label_img = label_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "        if self._rotate == 'ROTATE_90':\n",
    "            img = img.transpose(Image.ROTATE_90)\n",
    "            label_img = label_img.transpose(Image.ROTATE_90)\n",
    "            \n",
    "        if self._rotate == 'ROTATE_180':\n",
    "            img = img.transpose(Image.ROTATE_180)\n",
    "            label_img = label_img.transpose(Image.ROTATE_180)\n",
    "\n",
    "        if self._rotate == 'ROTATE_270':\n",
    "            img = img.transpose(Image.ROTATE_270)\n",
    "            label_img = label_img.transpose(Image.ROTATE_270)\n",
    "\n",
    "        # PIL image:   H x W x C\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        label_img = np.array(label_img, dtype=np.uint8)\n",
    "        np.place(label_img, label_img>0, 255)\n",
    "\n",
    "        if self._normalize:\n",
    "            img = (img - 128.0)/128.0\n",
    "   \n",
    "        return (img, x, y, label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T22:38:50.206022Z",
     "start_time": "2019-08-26T22:38:21.145265Z"
    }
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "start_time = time.time()\n",
    "experiment_id = 'incep_viable_80k'\n",
    "# mode = 'training' #training or validation\n",
    "mode = 'validation' #training or validation\n",
    "iteration = '0'\n",
    "kfold_k = 5\n",
    "fold = 0\n",
    "# batch_size = 64 \n",
    "batch_size = 64 \n",
    "mask_path = None\n",
    "image_size = 256\n",
    "mining_threshold = 0.6 #Lesser than which to mine points\n",
    "\n",
    "sampling_stride = image_size #At the 0 level\n",
    "\n",
    "#Model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "model = get_inception_resnet_v2_unet_softmax((None, None), weights=None)\n",
    "model_root_path = '../../results/saved_models/%s/' % (experiment_id)\n",
    "fold_path = os.path.join(model_root_path,'%dfold_%d'%(kfold_k,fold))\n",
    "# model_path = glob.glob(os.path.join(fold_path,'sel-model.*.h5'))[0]\n",
    "model_path = glob.glob(os.path.join(fold_path,'model.05-0.22.h5'))[0]\n",
    "print(\"Hardmining with model stored in %s\"% model_path)\n",
    "\n",
    "core_config = tf.ConfigProto()\n",
    "core_config.gpu_options.allow_growth = False\n",
    "# core_config.gpu_options.per_process_gpu_memory_fraction=0.46\n",
    "session =tf.Session(config=core_config) \n",
    "K.set_session(session)\n",
    "model.load_weights(model_path)\n",
    "print (\"Loaded Model Weights\")\n",
    "print(\"Hardmining with model stored in %s\"% model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T22:39:18.032557Z",
     "start_time": "2019-08-26T22:38:50.208279Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = get_inception_resnet_v2_unet_softmax((None, None), weights=None)\n",
    "model2.load_weights(glob.glob(os.path.join(fold_path,'sel-model.*.h5'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-26T22:41:50.609Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "#Get train ids from cv split file containing path to wsi images\n",
    "sample_ids = [ x.split('/')[-2] for x in list(pd.read_csv('../../data/raw-data/cross_val_splits_%d_whole/%s_fold_%d.csv'%(kfold_k,mode,fold))['Image_Path'])]\n",
    "for i,sample_id in enumerate(sample_ids[1:]):\n",
    "    # if i<6:\n",
    "        # continue\n",
    "    print(i,'/',len(sample_ids),sample_id)\n",
    "        \n",
    "    sample_dir = os.path.join('..','..','data','raw-data','train',sample_id)\n",
    "    wsi_path = glob.glob(os.path.join(sample_dir,'*.svs'))[0]\n",
    "    label_path = glob.glob(os.path.join(sample_dir,'*viable*.tiff'))[0]\n",
    "    dataset_obj = WSIStridedPatchDataset(wsi_path, \n",
    "                                        mask_path,\n",
    "                                        label_path,\n",
    "                                        image_size=image_size,\n",
    "                                        normalize=True,\n",
    "                                        flip=None, rotate=None,\n",
    "                                        level=2, sampling_stride=sampling_stride//16, roi_masking=True)\n",
    "    \n",
    "    meta_dict= {'num': 0, 'den': 0, 'jaccs':[]}\n",
    "\n",
    "    dataloader = DataLoader(dataset_obj, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "    dataset_obj.save_scaled_imgs()\n",
    "    \n",
    "    print(\"Total iterations: %d and %d\" % (dataloader.__len__(),dataloader.dataset.__len__()))\n",
    "    for i,(data, x, y, label) in enumerate(dataloader):\n",
    "        #print(i,x,y)\n",
    "        image_patches = data.cpu().data.numpy()\n",
    "        patch_mask = TissueMaskGenerationPatch(image_patches[0]*128+128)\n",
    "        label_patches = label.cpu().data.numpy()\n",
    "        \n",
    "        pred_map = model.predict(image_patches,verbose=0,batch_size=1)\n",
    "        pred_map2 = model2.predict(image_patches,verbose=0,batch_size=1)\n",
    "        for j in range(batch_size):\n",
    "            jacc_score = calc_jacc_score(labelthreshold(pred_map[j,:,:,1],threshold=0.45),label_patches[j])\n",
    "            meta_dict['jaccs'].append(jacc_score)\n",
    "            meta_dict['num']+=int(np.sum(labelthreshold(pred_map[j,:,:,1],threshold=0.45)*label_patches[j].clip(max=1)))\n",
    "            meta_dict['den']+=int(np.sum(np.logical_or(labelthreshold(pred_map[j,:,:,1],threshold=0.45),label_patches[j])))\n",
    "            \n",
    "            if jacc_score < mining_threshold:\n",
    "                tf = get_tumor_fraction(label_patches[j])\n",
    "                point_x = int(x[j]) + image_size//2\n",
    "                point_y = int(y[j]) + image_size//2\n",
    "                \n",
    "            #print(\"Jaccard: %.3f\" %(jacc_score))\n",
    "            imshow(pred_map[j,:,:,1],pred_map2[j,:,:,1],label_patches[j],np.uint8(image_patches[j]*128+128))\n",
    "            #imshow(pred_map[j,:,:,1],labelthreshold(pred_map[j,:,:,1],0.45),label_patches[j])\n",
    "                                                                         \n",
    "        if (i)%100==0:\n",
    "            print(\"Completed %i Time elapsed %.2f min\"%(i,(time.time()-start_time)/60))\n",
    "            print(meta_dict['num'],meta_dict['den'])\n",
    "    print(\"Completed %i Time elapsed %.2f min\"%(i,(time.time()-start_time)/60))\n",
    "    print(meta_dict['num'],meta_dict['den'])\n",
    "    meta_dict['jaccs_index'] = meta_dict['num']/meta_dict['den']\n",
    "    print(meta_dict['jaccs_index'])\n",
    "    meta_dict['histogram'] = str(np.histogram(meta_dict['jaccs'], bins=11))\n",
    "    with open(os.path.join(mined_points_path, sample_id+'.json'),'w') as f:\n",
    "        json.dump(meta_dict,f)\n",
    "    start_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
